diff --git a/inputs/comprehensive/resume_data.json b/inputs/comprehensive/resume_data.json
index e69de29..abc0001 100644
--- a/inputs/comprehensive/resume_data.json
+++ b/inputs/comprehensive/resume_data.json
@@
 {
-  "summary": "Comprehensive career overview...",
-  "competencies": { "All": ["Mix of skills"] }
+  "summary": "Comprehensive career spanning 15+ years across data engineering, applied research, consulting, and analytics. Blends hands-on technical expertise (ETL, Spark, dbt, Snowflake, ML/AI) with leadership, client engagement, and policy impact.",
+  "competencies": {
+    "Core Technical": ["Python", "PySpark", "SQL", "dbt", "Airflow", "Snowflake"],
+    "Research & Analysis": ["Survey Methodology", "Geospatial Modeling", "Segmentation"],
+    "Consulting": ["Data Strategy", "Client Leadership", "Decision Sciences"],
+    "Marketing": ["Consumer Insights", "Behavioral Analytics"],
+    "Leadership": ["Team Management", "Cross-Functional Delivery"]
+  },
+  "experience": [
+    {
+      "title": "Data Products Manager",
+      "company": "Helm/Murmuration, Austin, TX",
+      "dates": "2021–2023",
+      "responsibilities": [
+        "Designed and deployed a multi-tenant Snowflake data warehouse using dbt to support geo-demographic pipelines.",
+        "Modernized ETL with PySpark + dbt workflows, reducing pipeline runtime by 57% across multi-terabyte datasets.",
+        "Built data governance and quality frameworks for sensitive demographic/electoral data.",
+        "Developed scalable ETL pipelines for ML/AI processing, enabling predictive analytics across 10M+ records.",
+        "Led an 11-person cross-functional data engineering team, integrating CI/CD and Agile best practices."
+      ]
+    },
+    {
+      "title": "Partner",
+      "company": "Siege Analytics, Austin, TX",
+      "dates": "2005–Present",
+      "responsibilities": [
+        "Architected multi-tenant cloud data warehouses handling billions of geospatial and demographic records.",
+        "Engineered PySpark + dbt ETL pipelines enabling concurrent client access with high reliability.",
+        "Developed spatial clustering algorithms enhancing voter targeting by 88% and yielding 170% more viable targets.",
+        "Built fraud detection pipelines operating over multi-terabyte datasets for campaign finance analysis.",
+        "Created a scalable redistricting platform supporting thousands of users in court and policy environments."
+      ]
+    },
+    {
+      "title": "Analytics Supervisor",
+      "company": "GSD&M, Austin, TX",
+      "dates": "2018–2019",
+      "responsibilities": [
+        "Scaled the Decision Sciences Department from small-scale reporting to enterprise-level big data operations.",
+        "Implemented spatial analytics and clustering models that uncovered new customer insights.",
+        "Deployed version control (Git) and Agile workflows, cutting delivery times by 40%.",
+        "Managed and mentored 3 analysts in modern data engineering and statistical techniques."
+      ]
+    },
+    {
+      "title": "Software Engineer",
+      "company": "Mautinoa Technologies, Austin, TX",
+      "dates": "2016–2018",
+      "responsibilities": [
+        "Designed econometric simulation software for humanitarian crisis modeling.",
+        "Built data models and ETL pipelines for sensitive humanitarian datasets (UNICEF, IFRC).",
+        "Applied ML and statistical modeling to support large-scale impact assessments.",
+        "Conducted geospatial analyses on global populations and boundaries."
+      ]
+    },
+    {
+      "title": "Senior Analyst",
+      "company": "Myers Research, Austin, TX",
+      "dates": "2012–2014",
+      "responsibilities": [
+        "Developed survey operations web application handling end-to-end data collection and reporting.",
+        "Introduced geospatial analysis techniques to improve client segmentation and targeting.",
+        "Designed advanced survey instruments and analytical products delivering actionable insights."
+      ]
+    },
+    {
+      "title": "Research Director",
+      "company": "PCCC, Austin, TX",
+      "dates": "2011–2012",
+      "responsibilities": [
+        "Engineered innovative phone survey system supporting thousands of concurrent calls.",
+        "Developed new statistical methods for boundary estimation enhancing segmentation accuracy.",
+        "Led national-level survey design, deployment, and analysis with policy impact."
+      ]
+    }
+  ]
 }
 
diff --git a/inputs/technical/resume_data.json b/inputs/technical/resume_data.json
index e69de29..abc0002 100644
--- a/inputs/technical/resume_data.json
+++ b/inputs/technical/resume_data.json
@@
 {
-  "summary": "Research & Data Professional...",
+  "summary": "Data Engineer / Technical Architect with 15+ years designing scalable ETL pipelines, distributed data warehouses, and real-time analytics systems. Expert in Spark, dbt, Airflow, Snowflake, and geospatial data engineering.",
   "competencies": {
-    "Skills": ["Survey methodology"]
+    "Languages": ["Python", "SQL", "Scala"],
+    "Data Engineering": ["ETL Pipelines", "dbt", "Apache Spark", "Apache Airflow"],
+    "Data Warehousing": ["Snowflake", "PostgreSQL", "Redshift"],
+    "Cloud": ["AWS", "GCP", "Azure"]
   },
+  "highlights": [
+    "Reduced ETL runtime by 57% via dbt + PySpark modernization",
+    "Architected multi-tenant Snowflake warehouse processing billions of records",
+    "Developed geospatial clustering improving voter targeting by 88%"
+  ],
+  "experience_override": {
+    "Helm/Murmuration": { "prioritize": ["Designed and deployed multi-tenant Snowflake data warehouse", "Modernized ETL with PySpark + dbt workflows"] }
+  }
 }
 
diff --git a/inputs/research/resume_data.json b/inputs/research/resume_data.json
index e69de29..abc0003 100644
--- a/inputs/research/resume_data.json
+++ b/inputs/research/resume_data.json
@@
 {
-  "summary": "Researcher with 20 years...",
+  "summary": "Director of Research & Analysis with 15+ years in geospatial and demographic analytics. Expert in survey methodology, clustering models, and research pipelines that drive policy and social impact.",
   "competencies": {
-    "Skills": ["Polling"]
+    "Research Methods": ["Survey Design", "Polling", "Statistical Modeling"],
+    "Data Engineering": ["ETL", "Geospatial Pipelines", "Clustering Models"],
+    "Policy": ["Redistricting", "Electoral Studies", "Program Evaluation"]
   },
+  "highlights": [
+    "Developed statistical boundary estimation methods adopted in litigation",
+    "Led national-level survey design and analysis for political organizations",
+    "Engineered geospatial segmentation improving response accuracy by 25%"
+  ],
+  "experience_override": {
+    "PCCC": { "prioritize": ["Engineered phone survey system", "Developed new statistical methods for boundary estimation"] }
+  }
 }
 
diff --git a/inputs/software/resume_data.json b/inputs/software/resume_data.json
index e69de29..abc0004 100644
--- a/inputs/software/resume_data.json
+++ b/inputs/software/resume_data.json
@@
 {
-  "summary": "Software Engineer with diverse background...",
+  "summary": "Software Engineer and Data Systems Architect experienced in building production-grade APIs, simulation systems, and geospatial applications. Skilled in Python, Scala, and JavaScript with expertise in ETL and data-driven modeling.",
   "competencies": {
-    "Programming": ["PHP"]
+    "Programming": ["Python", "Scala", "JavaScript", "Groovy", "R"],
+    "Frameworks": ["Django", "GeoDjango", "React", "Node.js"],
+    "Data Systems": ["Spark", "PostgreSQL", "MongoDB", "Neo4j"],
+    "Modeling": ["Agent-Based Modeling", "Econometric Simulations", "ML/AI Pipelines"]
   },
+  "highlights": [
+    "Engineered econometric simulation system for humanitarian crises",
+    "Developed geospatial pipelines for NGO projects (UNICEF, IFRC)"
+  ]
 }
 
diff --git a/inputs/consulting/resume_data.json b/inputs/consulting/resume_data.json
index e69de29..abc0005 100644
--- a/inputs/consulting/resume_data.json
+++ b/inputs/consulting/resume_data.json
@@
 {
-  "summary": "Consultant with extensive experience...",
+  "summary": "Consultant & Data Strategist with 15+ years advising organizations on analytics, data infrastructure, and decision sciences. Partnered with political campaigns, NGOs, and Fortune 500 firms to translate complex datasets into actionable insights.",
   "competencies": {
-    "Advisory": ["Client Relationship"]
+    "Advisory": ["Data Strategy", "Decision Sciences", "Client Engagement"],
+    "Delivery": ["Cloud Data Warehousing", "Analytics Product Development", "Agile Project Management"],
+    "Technical": ["ETL", "PySpark", "Snowflake", "dbt", "Geospatial Analysis"]
   },
+  "highlights": [
+    "Led multimillion-dollar analytics projects under tight deadlines",
+    "Rebuilt data infrastructure for major advertising agency",
+    "Architected redistricting software adopted by thousands of analysts"
+  ]
 }
 
diff --git a/inputs/marketing/resume_data.json b/inputs/marketing/resume_data.json
index e69de29..abc0006 100644
--- a/inputs/marketing/resume_data.json
+++ b/inputs/marketing/resume_data.json
@@
 {
-  "summary": "Marketing analyst and strategist...",
+  "summary": "Marketing Data Engineer with experience applying segmentation, clustering, and advanced analytics to uncover consumer behavior insights. Skilled at bridging technical engineering with strategic marketing applications for major brands and agencies.",
   "competencies": {
-    "Marketing": ["Consumer insights"]
+    "Marketing Analytics": ["Segmentation Models", "Behavioral Clustering", "Campaign Analytics"],
+    "Data Engineering": ["ETL Pipelines", "Big Data Analysis", "Cloud Data Platforms"],
+    "Visualization": ["Tableau", "Looker", "Matplotlib", "Seaborn"]
   },
+  "highlights": [
+    "Built segmentation models driving multimillion-dollar ad campaigns",
+    "Restructured analytics department to scale from BI to big data",
+    "Applied geospatial analytics to improve customer targeting"
+  ]
 }
